{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as du\n",
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import csv\n",
    "from os import listdir\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Price_Dataset(IterableDataset):\n",
    "\tdef __init__(self, directory, window_size = 100, start = 0, end = 8):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.window_size = window_size\n",
    "\n",
    "\t\tprices = []\n",
    "\t\tfiles = listdir(directory)\n",
    "\t\tcsvs = [f'{directory}/{f}' for f in files if f.endswith('csv')][start:end]\n",
    "\t\tfor c in csvs:\n",
    "\t\t\twith open(c, 'r') as f:\n",
    "\t\t\t\tlines = list(csv.reader(f))[1:]\n",
    "\t\t\t\tprices.append(np.array([float(l[5]) for l in lines]))\n",
    "\t\tprices = np.array(prices)\n",
    "\t\tfor i, row in enumerate(prices):\n",
    "\t\t\tfor j, col in enumerate(row[:-1]):\n",
    "\t\t\t\tprices[i][j] -= prices[i][j+1]\n",
    "\n",
    "\t\tself.prices = prices\n",
    "\t\tself.length = int(len(self.prices)*(\n",
    "\t\t\t(len(self.prices[0]) - self.window_size-1)+(len(self.prices[0]) - self.window_size-1)//2+\n",
    "\t\t\t(len(self.prices[0]) - self.window_size-1)//3+(len(self.prices[0]) - self.window_size-1)//4+\n",
    "\t\t\t(len(self.prices[0]) - self.window_size-1)//5))\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.length\n",
    "\n",
    "\tdef __iter__(self):\n",
    "\t\tfor p in self.prices:\n",
    "\t\t\tfor k in np.arange(1, 5):\n",
    "\t\t\t\tfor offset in range(0, (len(p) - self.window_size-1)//k):\n",
    "\t\t\t\t\tout = torch.zeros(self.window_size)\n",
    "\t\t\t\t\tfor i in range(self.window_size):\n",
    "\t\t\t\t\t\tout[i] = np.sum(p[offset+i*k:offset+(i+1)*k])\n",
    "\t\t\t\t\tout = out.unsqueeze(1)\n",
    "\t\t\t\t\tlabel = np.sum(p[offset+self.window_size*k:offset+(self.window_size+1)*k])\n",
    "\t\t\t\t\tyield out, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_Model(nn.Module):\n",
    "    def __init__(self, d_model, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.trans = nn.Transformer(d_model=d_model)\n",
    "        # self.fc1 = nn.Linear() \n",
    "    def forward(self, x):\n",
    "        x = self.trans(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = f'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"using device: {device}\")\n",
    "epochs = 5\n",
    "learning_rate = 1e-4\n",
    "batch_size = 20\n",
    "window_size = 80\n",
    "# start = 0\n",
    "# end = 4\n",
    "\n",
    "train_dataset = Price_Dataset('Kline/filter', window_size=window_size)\n",
    "train_loader = du.DataLoader(dataset = train_dataset, batch_size = batch_size)\n",
    "\n",
    "net = Transformer_Model(window_size, 1, 1, 1)\n",
    "optimizer = optim.Adam(net.parameters(), lr = learning_rate)\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "a,b = next(iter(train_loader))\n",
    "# net = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/839 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'tgt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_752/430036050.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_752/4006847508.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m# self.fc1 = nn.Linear()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'tgt'"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1 , epochs + 1):\n",
    "    sum_loss = 0\n",
    "    for batch_idx, (price, label) in enumerate(tqdm(train_loader)):\n",
    "        price, label = price.to(device), label.unsqueeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = net(price)\n",
    "        print(pred.shape)\n",
    "\n",
    "    #     loss = loss_func(pred.float(), label.float())\n",
    "    #     loss.backward()\n",
    "\n",
    "    #     optimizer.step()\n",
    "\n",
    "    #     sum_loss += loss.item()\n",
    "\n",
    "    # print(f'Epoch {epoch}: Train loss: {sum_loss/batch_idx/batch_size:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c788f194a8dbf5562e4840f2c870f984b853315244ea6daf65a3e4344976d39c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
